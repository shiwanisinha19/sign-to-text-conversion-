# Sign-to-text-conversion-using-openCV
Hello, This repository contains python implementation for recognising American Sign Language (ASL) gestures. As there is less research, there is no standard dataset avialable in the web. So, we decided to create my own dataset of gesture images. ASL dataset have all alphabets (A-Z) with total classes = 26. Each class has 1200 images.  
We are developing a system that uses our computerâ€™s webcam to capture our hand gestures for American Sign Language (ASL), and translate it into corresponding text. We will not be using glove or any external hardware for our system, our model can recognize gestures made by bare hands. This system uses a set of representations which are finger sign, expression or mixture of both to precise their information among others. The system proposed in this project aims at tackling the problem of requirement of interpreter to some extent by recognizing sign language and converting it to text. Input given to the system is an image of the hand depicting the necessary alphabet. Our system uses deep learning techniques. One such technique is Convolutional Neural Network (CNN) for image depiction and classification. Our system uses OpenCV for the real time computer vision. The main aim behind our project is to develop a system which provides communication between people with speech disabilities and normal people. Our system is able to 
recognize 26 American Sign Language (ASL) alphabets.
